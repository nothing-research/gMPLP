{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_c5X9Pvj4MX"
   },
   "source": [
    "## Giới thiệu\n",
    "\n",
    "Transfromer trong những năm gần đây đã làm thay đổi các chúng ta tiếp cận và giải quyết các bài toán thị giác máy tính như (Vision Transformer, Swin Transfromer, ...). Bên cạnh đó các kiến trúc tập trung vào attention ở trên thì các kiến trúc không sử dụng cơ chế attention như FNet, gMLP (gated Multilayer Perceptron) nổi lên như một phương pháp đầy tiềm năng, tận dụng sức mạnh và sự đơn giản của các lớp MLP thay vì phụ thuộc vào chú ý. gMLP hoạt động dựa trên cơ chế Spatial Gating Unit (SGU), một thành phần tinh gọn nhưng hiệu quả trong việc học các mối quan hệ không gian giữa các token mà không cần tới self-attention. Tuy nhiên, các hạn chế của gMLP trong việc mở rộng khả năng biểu diễn và xử lý các đặc điểm phức tạp vẫn là một rào cản lớn khi so sánh với các mô hình tiên tiến như Swin Transformer hoặc các kiến trúc hiện đại dựa trên CNN.\n",
    "Để khắc phục những hạn chế này, nghiên cứu đề xuất một phiên bản cải tiến của gMLP, sử dụng các đặc trưng đa thức (trong nghiên cứu này sẽ sử dụng bậc 2) gọi là gMPLP.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## Ý tưởng\n",
    "- Cho một input batch $ x \\in \\mathbb{R}^{N \\times H \\times W \\times C} $. Nghiên cứu sử dụng $ (H, W) = (256, 256) $.\n",
    "- Chia các hình ảnh đầu vào thành các ***patches*** và reshape. Với ***patch size = 16*** $\\Rightarrow$ thu được $z$ có shape: $ (N, number\\_of\\_patches, patch\\_height \\times patch\\_width \\times C) $.\n",
    "\n",
    "Nghiên cứu sử dụng một layer thực hiện các hoạt động sau:\n",
    "\n",
    "- Chuẩn hóa: $ \\overline{z} \\leftarrow LN(z) $ \\\\\n",
    "trong đó: $ LN $ là Layer Normalization.\n",
    "- Tạo đặc trưng đa thức: $ p = [z, z^2, z^3,..., z^d] $. Với $d$ là bậc của đa thức.\n",
    "- Áp dụng một phép chiếu tuyến tính với $p$:\n",
    "$$ p \\leftarrow p \\cdot W + b $$\n",
    "với $W$ là ma trận trọng số và $b$ là bias vector.\n",
    "- Chuẩn hóa lần 2: $ p \\leftarrow LN(p) $\n",
    "- Áp dụng activation: $ output = activation(p) $. Ở đây activation có thể là $gelu$ hoặc $linear$.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HqedRE9-Zn7"
   },
   "source": [
    "## Xây dựng gMPLP block từ layer trên:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gMPLP](MPLP_image.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dữ liệu:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U6m0TvBSIxIN"
   },
   "source": [
    "- [https://ieee-dataport.org/documents/brain-tumor-mri-dataset](https://ieee-dataport.org/documents/brain-tumor-mri-dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pW5mMxpbHLJO"
   },
   "source": [
    "- Số lượng ảnh dùng để huấn luyện:\n",
    "    - training: 5712\n",
    "    - validation: 571\n",
    "    - testing: 1311\n",
    "\n",
    "- Huấn luyện với 25 epochs. 15 epochs đầu tiên $learning\\_rate = 1e-3$. 10 epochs sau $learning\\_rate = 1e-4$\n",
    "- L4 GPU\n",
    "\n",
    "- Huấn luyện và so sánh gMLP và gMPLP. mô hình gMLP sẽ được mở rộng theo chiều rộng (số units trong phép chiếu tuyến tính) và chiều sâu (số gMLP blocks) để có số lượng tham số tương đương với gMPLP.\n",
    "    - Số chiều nhúng (embedding_dim) của gMLP: 320, số blocks: 4.\n",
    "    - Số chiều nhúng (embedding_dim) của gMPLP: 256, số blocks: 2.\n",
    "\n",
    "- Huấn luyện và so sánh ViT và ViT + gMPLP. Thay thế khối MLP bình thường trong ViT cho thành khối gMPLP cho model ViT + gMPLP.\n",
    "    - Số chiều nhúng (embedding_dim) của ViT: 160, số Transformer blocks: 2.\n",
    "    - Số chiều nhúng (embedding_dim) của ViT + gMPLP: 160, số Transfromer blocks: 1.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AgK8N4gYSgOd"
   },
   "source": [
    "## Kết quả"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gMLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gMLP](gMLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gMPLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![gMPLP](gMPLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBpPPDndTKFZ"
   },
   "source": [
    "### ViT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ViT](ViT.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgiuPrlyW1q5"
   },
   "source": [
    "### ViT + gMPLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ViT + gMPLP](ViT_gMPLP.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bảng so sánh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![compare_tb](compare_tb.png)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNuUtY8kf9wZNjNLE2usGbv",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
